\documentclass[onecolumn]{aastex61}
\pdfoutput=1 %for arXiv submission
\usepackage{amsmath,amstext}
\usepackage[T1]{fontenc}
\usepackage{apjfonts} 
\usepackage[figure,figure*]{hypcap}

\renewcommand*{\sectionautorefname}{Section} %for \autoref
\renewcommand*{\subsectionautorefname}{Section} %for \autoref

\definecolor{dred}{rgb}{0.75,0,0}
\definecolor{darkred}{rgb}{0.5,0,0}
\definecolor{darkgreen}{rgb}{0,0.5,0}
\definecolor{darkblue}{rgb}{0,0,0.5}
\hypersetup{ colorlinks,
linkcolor=darkblue,
filecolor=darkgreen,
urlcolor=darkred,
citecolor=darkblue}

\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\beq}{\begin{equation}}
\newcommand{\eeq}{\end{equation}}

\newcommand{\project}[1]{{\textsl{#1}}}
\newcommand{\sdss}{\project{SDSS}}
\newcommand{\boss}{\project{BOSS}}
\newcommand{\hst}{\project{HST}}
\newcommand{\wfc}{\project{WFC3}}

\shorttitle{wfc3-ir super-sampled psf}
\shortauthors{Vakili, Fadely, and Hogg}

\begin{document}

\title{Inference of the Super-resolution PSF model of HST WFC3-IR Channel}

\author{Mohammadjavad~Vakili}
\affiliation{Center for Cosmology and Particle Physics, Department of Physics, New York University, 726 Broadway, New York, NY, 10003}
\author{Ross~Fadely}
\affiliation{Center for Cosmology and Particle Physics, Department of Physics, New York University, 726 Broadway, New York, NY, 10003}
\affiliation{Insight Data Science, New York, NY}
\author{David~W.~Hogg}
\affiliation{Center for Cosmology and Particle Physics, Department of Physics, New York University, 726 Broadway, New York, NY, 10003}
\affiliation{Flatiron institute, 160 5th Avenue, New York, NY, 10010}
\affiliation{Center for Data Science, New York University, 60 5th Ave, New York, NY, 10010}
\affiliation{Max-Planck-Institut f\"ur Astronomie, K\"onigstuhl 17, D-69117 Heidelberg, Germany}

\begin{abstract}
Achieving an accurate model of the Point Spread Function is crucial for many applications such as reliable point source photometry, astrometry, and weak lensing studies.
The PSF model of the $\hst$ $\wfc$ IR channel does not meet the accuracy required by these science goals. 
In addition, the PSF of the $\hst$ $\wfc$ IR channel is poorly sampled. Weak lensing studies of poorly resolved images of faint distant galaxies demand 
excellent knowledge of the PSF sampled at a resolution higher than that of the $\hst$ $\wfc$ pixels.

In this work, we present a generative forward model of images taken by the $\wfc$ IR channel as a set of a number of point sources convolved
with the instrument PSF. We focus on modeling the pixel-convolved PSF, which is the optical PSF convolved with the pixel response function. 

%We expect the inference of the super-resolution PSF in other filters of the IR channel to follow a similar procedure. 
We discuss how the optimal solution of the problem can be found by adopting a variance model that correctly takes into account the model uncertainty, a regularization term that imposes a smoothness condition on the super-resolution PSF, and masking strategy for reducing the impact of overlapping sources on likelihood optimization.

In order validate this model, first we generate a set of realistic under-sampled images of point sources with an assumed higher resolution PSF. We then use our model to accurately recover this simulated PSF from the generated images. Afterwards, we apply our methodology to model the the images of point sources observed by the $\hst$ $\wfc$ IR channel in the \emph{F160W} bandpass. 

\end{abstract}

\keywords{methods: data analysis ---techniques: image processing}

\section{Introduction}

The Point Spread Function (hereafter PSF) determines the fraction of photons from a given point source that land at a particular displacement 
from the center of that point source on a detector. The PSF of the $\hst$ $\wfc$ camera is under-sampled. That is, if a center of an observed star lies 
on the center of a pixel, a significant fraction of the brightness of that star will be 
encapsulated by the single pixel that contains the centroid of the star.
In other words, within the full-width half-maximum (FWHM), the PSF is usually not spanned by multiple detector pixels since the pixels are large. 
This is mainly the result of a compromise made in design of the detectors to cover a wider field of view.

Poor sampling of the PSF by detectors renders many astronomical image processing tasks difficult. Precise astrometry and photometry 
of individual point sources requires knowledge of the PSF sampled at a higher resolution than that of the detector pixels. 
In uncalibrated observations, the images of stars are generated by convolution of the point sources with the PSF and multiplication 
with a non-uniform detector sensitivity called the \emph{flat-field}. Flat-field corrections are important for photometry and astrometry of 
individual point sources. In under-sampled images, capturing the sub-pixel variations of the flat-field requires having a high resolution 
model of the PSF. 

Furthermore, cosmic shear studies require accurate measurement of the shapes of individual distant galaxies. The galaxies used for estimation 
of the cosmic shear signal are faint and often barely resolved by the $\hst$ $\wfc$ detectors. In order to reliably measure the shapes of these poorly 
resolved galaxies, we need to convolve the model describing the light distribution of these galaxies with a higher resolution PSF model. 
Therefore, knowing the high resolution PSF is an essential ingredient in weak lensing studies of galaxies detected by the $\hst$ $\wfc$ IR 
channel.   

In this investigation, we focus on modeling the \emph{pixel-convolved PSF}, which is the optical (instrumental) PSF convolved with the 
pixel response function. It is the pixel-convolved PSF that can be directly estimated from observation without making any assumption 
about the sensitivity of detector pixels. Moreover, it is the pixel-convolved PSF that can be used to perform astrometry and photometry measurements as well as 
galaxy shape measurement for weak lensing analyses. All of these involve fitting a model to the pixel-convolved PSF. 

Another benefit of working with the pixel-convolved PSF is that the centers of pixels simply sample the PSF. That is, no integration of the 
optical PSF is required to evaluate the model of the images of point sources in observations.

Alternatively, one can deliver a model of the optical (instrumental) PSF based on physical models of the telescope optics. 
This involves measurement or prediction of the optical wavefront at all locations across the focal plane and the use of physically motivated parameters 
to model the image produced by the wavefront. Significant progress has been made in exploring the space of physical models that can reasonably 
describe the optical PSF \citep{zernike,krist1995,krist2011,galsim_software}. 

Development of optical models of the PSF are valuable efforts for simulation, validation, and understanding of the systematic uncertainties 
that can affect astronomical inferences \citep{great3,galsim}. In practice, however, using the optical PSF for photometry, astrometry and weak lensing studies 
requires fitting a star's model to the wavefront PSF model. The major drawbacks of this approach are the following: $(i)$ This approach does not make use of the available observed 
data, and $(ii)$ it makes strong assumptions about the sensitivity of detector pixels when it is used for model fitting. Therefore we attempt to build a 
data-driven or empirical model of the PSF. From now on in this paper, we refer to the pixel-convolved PSF as the PSF. 

This paper is structured as follows: In Section~\ref{sec:hstdata} we discuss the observations and data reduction. In Section~\ref{sec:hstmethod} we discuss the algorithm we 
have developed for inferring the super-resolution PSF model of the $\hst$ $\wfc$ IR channel observations. In Section~\ref{sec:hstresults} we present the preliminary results, and %FIXME
in Section~\ref{sec:hstsummary} we summarize and conclude.

\section{Data}\label{sec:hstdata}
The $\wfc$ IR camera takes images through four filters: F105W, F125W, F140W, F160W.
In what follows in the rest of this work we focus on modeling the images of point sources in the F160W filter of $\hst$ $\wfc$ IR channel. 
In our analysis, we make use of the FLT images that are calibrated with the recent models of charge transfer efficiency, flat-field, etc. 
We choose not to use drizzled images \citep{drizzle,astrodrizzle} because they introduce correlated noise and 
distortions to the PSF that are not consistent across the image (a new algorithm developed by \citealt{olic} for the WFIRST mission does not suffer from these issues). 
These distortions pose a challenge for optimal extraction of the PSF information and accurate measurement of shapes of galaxies. Therefore we find the pixels in the FLT images to be better-suited for PSF modeling. 

For each FLT image, we follow the following procedure to select stars with sufficiently high signal-to-noise ratio 
for PSF modeling. First the Source Extractor software \citep{sextractor} is run on each image to detect the objects. 
For each object, the stellarity index and blending/error flags are extracted. An object is called a \emph{star} if no blending/error flag is 
raised, its stellarity index is greater than 0.8, and if its peak pixel brightness value is 25 times greater than the median pixel brightness 
value. The Source Extractor configuration file used in our analysis is shown in Table~\ref{tab:sextractor}. 

The FLT files obtained from the HST MAST archive \footnote{\url{https://archive.stsci.edu}} are accompanied by Data Quality extension files. 
While extracting the super-resolution PSF model from the point sources in FLT images, pixels with data quality other than zero are flagged and we do not include them in model fitting. This requirement ensures that the damaged pixels do not contribute to the PSF model. For each point source, we extract a 25 pixels $\times$ 25 pixels patch that is centered on the brightest pixel of the point source. The Neural-Network weights for Source Extractor star-galaxy separation is available in \url{https://github.com/mjvakili/supermean/blob/master/default.nnw}.

%\clearpage

\begin{table}
\begin{center}
  \label{tab:sextractor}
  \caption{{\bf Source Extraction}: Source Extractor configuration file for extraction of the point sources from the $\hst$ $\wfc$ IR.}
\begin{tabular}{@{}lllll}
\\ \hline 
    Configuration Parameter & & Value & &  Description\\ \hline
  $\mathtt{DETECT \; TYPE}$ & & CCD & &  CCD (linear) or PHOTO (with gamma correction) \\
  $\mathtt{DETECT \; MINAREA}$ & & 5 & &  minimum number of pixels above threshold \\
  $\mathtt{DETECT \; THRESH}$ & & 5 & &  sigmas in $\mathrm{mag.arcsec}^{-2}$ \\
  $\mathtt{ANALYSIS \; THRESH}$ & & 1.5 & & sigmas in $\mathrm{mag.arcsec}^{-2}$  \\
  $\mathtt{FILTER}$ & & N & &  apply filter for detection?\\ 
  $\mathtt{DEBLEND \;  NTHRESH}$ & & 32 & &  Number of deblending sub-thresholds \\
  $\mathtt{DEBLEND \; MINCONT}$ & & 0.005 & &  Minimum contrast parameter for deblending \\
  $\mathtt{CLEAN}$ & & Y & &  Clean spurious detections?\\
  $\mathtt{CLEAN \; PARAM}$ & & 1.0 & & Cleaning efficiency \\
  $\mathtt{MASK \; TYPE}$ & & CORRECT & &  type of detection MASKing \\
  $\mathtt{FLAG \; IMAGE}$ & & flags.fits & &   \\
  $\mathtt{FLAG \; TYPE}$ & & AND & &   \\
  $\mathtt{WEIGHT \; GAIN}$ & & N & &   \\
  $\mathtt{WEIGHT \; IMAGE}$ & & variance.fits & &  \\
  $\mathtt{WEIGHT \; TYPE}$ & & MAP VAR & &  \\
  $\mathtt{PHOT \; APERTURES}$ & & 3,5,7 & &  MAG APER aperture diameter(s) in pixels \\
  $\mathtt{PHOT \; AUTOPARAMS}$ & & 2.5, 3.5 & &  MAG AUTO parameters: Kron fact, min radius \\
  $\mathtt{PHOT \; PETROPARAMS}$ & & 2.0, 3.5 & &  MAG PETRO parameters: Petrosian fact , min radius \\
  $\mathtt{PHOT \; FLUXFRAC}$ & & 0.2, 0.5, 0.9 & &   \\
  $\mathtt{SATUR \; LEVEL}$ & & 50000.0 & &  level (in ADUs) at which arises saturation \\
  $\mathtt{MAG \; ZEROPOINT}$ & & 1.0e-19  & &  magnitude zero-point \\
  $\mathtt{MAG \; GAMMA}$ & & 4.0 & &  gamma of emulsion (for photographic scans) \\
  $\mathtt{GAIN}$ & & 0.0 & &  detector gain in $e-/ADU$ \\
  $\mathtt{PIXEL \; SCALE}$ & & 0.13 & &  size of pixel in arcsec\\
  $\mathtt{SEEING \; FWHM}$ & & 0.17 & &  stellar FWHM in arcsec \\
  $\mathtt{STARNNW \; NAME}$ & & ``./default.nnw'' & &  Neural-Network Weight table filename \\
  $\mathtt{BACK \; SIZE}$ & & 64 & &  Background mesh: size \\
  $\mathtt{BACK \; FILTERSIZE}$ & & 3 & &  Background filter: size \\
  $\mathtt{BACKPHOTO \; TYPE}$ & & GLOBAL & &  Background type: can be GLOBAL or LOCAL \\
  %$\mathtt{CHECKIMAGE TYPE}$ & & NONE & &   \\
  %$\mathtt{CHECKIMAGE NAME}$ & & check.fits & &   \\
  %$\mathtt{MEMORY OBJSTACK}$ & & 3000 & &  number of objects in stack \\
  %$\mathtt{MEMORY PIXSTACK}$ & & 300000 & &  number of pixels in stack \\
  %$\mathtt{MEMORY BUFSIZE}$ & & 1024 & &  number of lines in buffer \\
  %$\mathtt{VERBOSE TYPE}$ & & QUIET & &  can be QUIET, NORMAL or FULL \\
  %$\mathtt{WRITE XML}$ & & N & &  Write XML file (Y/N)? \\
  %$\mathtt{XML NAME}$ & & sex.xml & &  Filename for XML output \\
 \hline
  \end{tabular}
\end{center}
\end{table}

%\clearpage

\section{Method}\label{sec:hstmethod}
In this section, we describe the generative model we use to infer the 
pixel-convolved Point Spread Function of the F160W filter. 
Under the assumption that the pixels are not correlated, the brightness of 
every pixel in a given patch of sky is given by 
\beq
y_i = g N_i + e_i,
\eeq
where $N_i$ is the number of photons landing on pixel $i$, $g$ is the instrument gain which is determined by the quantum efficiency of the detector, and $e_i$ is the per-pixel noise of pixel $i$ resulting from sky or the electron read-out. 
$N_i$ is a random variable which is drawn from a Poisson distribution. The expected value of $N_i$ is the model evaluated at pixel $i$
\beq
N_i \sim \text{Poisson} \; (m_i),
\eeq
where $m_i$ is determined by the expected number of photons from the background sky and the astronomical objects (point sources in this study) that land on pixel $i$ at a given time interval, as well as the pixel-convolved PSF. 
In the limit of a large number of photons, the central limit theorem implies that 
$N_i$ must be Gaussian distributed with a mean and a variance given by $m_i$. 
Therefore, $gN_i$ is Gaussian-distributed random variable with a mean and a variance given by $gm_i$:

\begin{eqnarray}
gN_i &\sim& \mathcal{N}(\tilde{\mu}_i , \tilde{\sigma}_i^2), \;\;\; \text{for large}\;\;\; N_i\\
\mu_i &=& \sigma_i^2 = gm_i
\end{eqnarray}
On the other hand, $e_i$ can be well described by a random variable with Gaussian distribution 
\beq
e_i \sim \mathcal{N}(0 , \sigma^2).
\eeq
As a result, we can write down the underlying distribution of 
the brightness of every detector pixel
\begin{eqnarray}
y_i &\sim& \mathcal{N}(\mu_i , \nu_i^{2}), \label{eq:yi1} \\
\mu_i &=& gm_i, \label{eq:yi2} \\
\nu_i^{2} &=& \sigma^{2} + gm_i. \label{eq:yi3} 
\end{eqnarray}

Equations~\ref{eq:yi1},~\ref{eq:yi2},~\ref{eq:yi3} imply that the brightness of 

\subsection{patch fitting}

We aim to infer the super-resolution PSF of the $\wfc$-IR channel by optimizing a forward model 
of point sources observed by this instrument. As we described in Section~\ref{sec:hstdata}, the final 
data product used in this study is a set of 25 pixels $\times$25 pixels patches centered around point sources. 

Let us denote this data vector by $\{\mathbf{d}_{n}\}_{n=1}^{N_\text{patches}}$, where $N_\text{patches}$ is the total number of patches. In other words, $\mathbf{d}_{n}$ is the observed 625-dimensional vector describing the brightness of the pixels in the 25 pixels $\times$ 25 pixels patch $n$. Assuming that the model and the noise model describing patch $n$ are given by two 625 dimensional vectors $\mathbf{m}_{n}$ and $\mathbf{s}_{n}$, we have:
\begin{eqnarray}
\mathbf{d}_{n} &=& \mathbf{m}_{n} + \mathbf{s}_{n}, \label{eq:model1} \\
s_{n,i} &\sim& \mathcal{N} (0 , \sigma^2 + g m_{n,i}), 
\end{eqnarray}
where $s_{n,i}$ and $m_{n,i}$ denote the i-th components of the vectors $\mathbf{s}_{n}$ and $\mathbf{m}_{n}$ respectively.

We build our empirical model of the point sources $\{\mathbf{m}_{n}\}_{n=1}^{N_\text{patch}}$ by assuming that a given point source at the center of a patch can be described by the following quantities: 

\begin{itemize}
\item A global solution for the super-resolution PSF $X$ that is shared between all point sources across the field of view. We assume 
that $X$ is normalized to one and it is centered at the center of the central pixel of the patch. This super-resolution PSF is sampled on 
a grid with a higher resolution than the native pixel grid of $\hst$ $\wfc$ IR observations.

\item Centroid coordinate of a point source at a given patch $\Delta_n = (\Delta x_n, \Delta y_n)$. 
These two parameters dictate the offset between the position of the centroid of the point source $n$ with 
respect to the center of the patch. Because we have centered our 25 $\times$ 25 patches on the brightest pixel, we expect these offsets to be small.

\item Flux quantity $f_n$ which is related to the brightness of the point source in each patch.

\item A background quantity $b_n$ which sets the brightness level of the background sky in each patch.
\end{itemize}

Given these ingredients, we write down the generative forward model of the point sources in the center of patches in the following way:

\beq 
 m_{n,i} = f_{n}K^{(n)}_{il} (\Delta_n) X_{l} + b_{n}. 
\label{eq:model}
\eeq

In Eq.~\ref{eq:model}, the operator $K^{(n)}(\Delta_n)$ is a linear operator that maps the super-resolution PSF $X$ to a downsampled PSF at the native 
data grid. That is, when this operator acts on $X$, it samples $X$ on a downsampled grid (with the same resolution as the observations) 
that is shifted with respect to the grid on which $X$ is defined. The shift between the two grids is given by the vector $\Delta_n = (\Delta x_n , \Delta y_n)$.


We want to be able to explicitly construct these matrices so we can analytically compute the likelihood function and its derivative with respect to the super-resolution PSF $X$. 
We implement the linear sampling operator $K$ with bivariate cubic-spline interpolation. By comparing our implementation of cubic-spline with that of the open source 
software $\mathtt{scipy}$ we note that they have consistent performances.

It is worth noting that there exist many possibilities for designing the sampling operator $K$.  The simplest and fastest approach that one could 
choose is bilinear interpolation. But after applying this method to simulated PSFs, we find that this method lacks the accuracy we 
need. Ideally, one could use a sinc interpolation \citep{bickerton,galsim}, which is an optimal choice for preserving information.
But we find sinc interpolation to be computationally demanding. Under same assumptions, we experimented with Gaussian Process interpolation for designing the downsampling matrix $K$, but Gaussian Process interpolation requires additional computing time to set hyper parameters.

The factor by which the PSF is undersampled varies from one filter to another. Our strategy for inferring the super-resolution of the PSF model of F160W filter is as follows. 
We aim to estimate $X$ on a 75 pixels $\times$ 75 pixels grid, which is a resolution three times that of the native pixel grid of the observations.

\subsection{likelihood optimization}

Now that we have explained the quantities needed to describe the generative model of $\wfc$ IR observations, we 
present our strategy for estimating the values of the parameters of individual point sources $\{f_{n},b_{n},\Delta_{n}\}_{n=1}^{N}$ and 
the global solution of the super-resolution PSF $X$.


In order to estimate the PSF, we optimize the following likelihood function with respect to the parameters $\{f_{n},b_{n},\Delta_{n}\}_{n=1}^{N}$ and the PSF solution $X$:

\begin{eqnarray} -2 \ln L &=& -2 \sum_{n=1}^{N_{patches}} \ln L_{n} \label{eq:total} , \\
-2 \ln L_{n} &=& \sum_{i=1}^{N_{\rm pix}} \Big( \frac{\big(d_{n,i} - m_{n,i} \big)^{2}}{s^{2}_{n,i}} + \ln(2 \pi s_{n,i}^{2}) \Big) \label{eq:patch},
\end{eqnarray}
where $L_{n}$ is the likelihood of patch $n$, $L$ is the likelihood of the entire astronomical scene.

It is important to note that our forward model of the $\wfc$ IR 
observations given by Eq.~\ref{eq:model} suffers from multiple degeneracies. The first degeneracy is between 
the flux values $\{f_n\}$ and the super-resolution PSF $X$. This degeneracy will prevent us from finding a unique 
solution for $\{f_n\}$ and $X$. This degeneracy can be broken by introducing a regularization term to Eq.~\ref{eq:total} that imposes 
smoothness condition to $X$. 

We add the following term to the log-likelihood $L$
\beq
C_{\rm reg} = -2\ln L + \epsilon \sum_{j,k} \delta^{2}_{j,k},
\label{eq:reg}
\eeq
where the second term is the sum of the squared of the matrix $\delta$ whose $j,k$ components are given by the difference between the $j$th row and $k$th column of the super-resolution PSF 
and its nearest pixels. The prefactor $\epsilon$ sets the strength of the regularization term. This enforces our prior belief that the PSF should be a smoothly varying object.

The second type of degeneracy is between the centroid offsets $\{\Delta_n\}$ and the super-resolution PSF $X$. In order to lift this degeneracy, we do not add any regularization 
term. Instead, throughout the optimization procedure we enforce a set of conditions that break this degeneracy. These conditions enforce the super-resolution 
PSF to be normalized and centered around the central pixel of the higher resolution grid. 

For inference of the PSF, we follow an optimization procedure similar to the method of Expectation Maximization (EM). In the context of astronomy, EM has been employed in extreme deconvolution \citep{xd} and heteroscedastic matrix factorization \citep{hmf}. Finding the optimal solution of 
$X$ and $\{f_n , b_n , \Delta_n\}$ proceeds as follows. 

First we initialize the parameters $X$ and $\{f_n , b_n , \Delta_n\}$. We initialize the centroid offsets ${\Delta_n}$ by the matched-filter polynomial centroiding 
described in Chapter 1. In particular, we correlate a Gaussian kernel with FWHM of 2.0 pixels with the 5 $\times$ 5 central pixels of each patch before applying 
the polynomial centroiding method. The reason for why we apply the polynomial method to the central pixels of each patch is that many of the stars in our $\hst$ observations 
are in crowded fields and therefore applying the matched-filter centroiding method to the entire patch could lead to biases as a result of light contamination from overlapping 
or nearby sources. 

The initial background values $\{b_n\}$ are estimated by taking the median pixel value in each patch. For initializing the flux values $\{f_n\}$, first we subtract the initial 
estimates of background values from each patch. Afterwards, the $\{f_n\}$ values are initialized by computing the sum of the pixel values within 5$\times$5 apertures centered on 
the central pixels of the patches. The reason for limiting our initialization of the flux estimates to the 5$\times$5 apertures is to prevent contamination of fluxes from 
overlapping and nearby sources. Besides, since the PSF is poorly sampled, we expect the majority of the flux to be captured by a few pixels around the centers of the patches. 

Lastly, the super-resolution PSF $X$ is initialized in the following way. First we subtract our initial estimates of the sky background levels from the patches. Then we divide the 
pixel values of the patches by their corresponding initial flux estimates. Then we use the cubic-spline interpolation method to interpolate the rescaled patches to a high resolution 
75 $\times$ 75 grids that are shifted by $\{-\Delta_n\}$ with respect to the patch centers. Afterwards, we evaluate the mean of the interpolated rescaled patches 
to estimate the initial PSF. Furthermore, we normalize the PSF and interpolate it such that it is centered on the central pixel of the 75 $\times$ 75 high resolution grid.  

Now that we have initialized the parameters of our model, we present the EM algorithm for optimizing them. At every iteration, we follow this 
iterative scheme. In the $n$th patch, we update $b_n$ by optimizing $L_n$ while holding $\{f_n, \Delta_n, X\}$ fixed. Then 
we update $f_n$ by optimizing $L_n$ while holding $\{b_n, \Delta_n, X\}$ fixed. Then we update $\Delta_n$ by holding $\{f_n, b_n, X\}$ fixed. 
Once $\Delta_n$ is updated, we update the sampling matrix $K^{(n)}$ accordingly. 

After updating $\{b_n, f_n, \Delta_n\}$ for all patches, we update $X$ 
by optimizing the regularized cost function $C_{\rm reg}$ given in Eq.~\ref{eq:reg}. At every iteration, we normalize the super-resolution PSF and 
interpolate it such that it is centered on the center of the 75 $\times$ 75 grid. We repeat these iterations until the value of regularized cost function 
$C_{\rm reg}$ converges.

\subsection{Addressing light contamination by nearby sources}

So far we have not addressed the problem of how our generative forward model of the patches takes into account the contamination arising from overlapping 
or nearby sources. In order to alleviate this issue, we introduce an additional noise model for identifying and masking out pixels that are 
in ill-fit portions of the patches.

The variance of this noise model is given by
\beq
\tilde{\mathbf{s}}_n^2 = \sigma^{2} + g\mathbf{m}_{n} + q\mathbf{m}_{n}^{2},
\label{eq:modified_variance}
\eeq 
which is similar to the variance given by Eq.~\ref{eq:variance} but with an additional term is 
proportional to the squared, downsampled model describing the patch. This accounts for possible discrepancies between the downsampled PSF model of the 
point source at the center of the patch and the observed pixels. That is, it is an effective model ``wrongness term'' term. 

This variance is used in a $\chi^2$ clipping technique to mask out ill-fit portions of the patches. 
This clipping step will prevent the the pixels affected by nearby sources to bias the inferred parameters.
In particular, after every model realization we identify the pixels that are not faithfully represented by the model and mask them so they do not 
contribute to computation of the patch likelihood function (\ref{eq:patch}).
 
At every iteration of optimizing the patch log-likelihood function, we mask out the pixels for which a clipped $\chi^{2}$ 
(denoted by $\chi^{2}_{clip}$ from now on) is larger than 3. For a given patch $n$, the clipped $\chi^{2}$ is defined in the following way:
\beq
\chi^{2}_{n,\mathrm{clip}} = \frac{(\mathbf{d}_{n} - \mathbf{m}_{n})^{2}}{\tilde{\mathbf{s}}_{n}^{2}}, 
\label{eq:chi_clip}
\eeq
where $\tilde{\mathbf{s}}_{n}^{2}$ is given by Eq.~\ref{eq:modified_variance}. In a given patch $n$, the log-likelihood pixels with $\chi^{2}_{n,\mathrm{clip}} > 3$ 
do not contribute to computation of $L_n$ and its derivatives with respect to model variables. 
We set the parameter $q$ to 1. We note that this choice of does a good job at masking out the pixels that receive light from the nearby or overlapping sources. 
In principle $q$ needs to decrease iteratively as our knowledge of the PSF improves. In this work however, we choose to hold the value of $q$ fixed at one. 

\subsection{Setting the smoothness regularization}

Note that we also need to set the strength of the smoothness regularization term $\epsilon$. Here, we can take advantage of the patches that were not used 
in training the PSF model to perform cross-validation. Cross-validation can be done in the following way. A set of values $S_{\epsilon}$ for the parameter $\epsilon$ need to be selected. For every $\epsilon$ in $S_{\epsilon}$, the optimization procedure as described above can be followed to to estimate $X_{\epsilon}$ which is the estimated $X$ corresponding to $\epsilon$. 

Then one can optimize the patch negative log-likelihood $-2\ln L_n$ given in Eq.~\ref{eq:patch} to find a solution for $\{f_n,b_n,\Delta_n\}$
variables for every patch in the cross-validation set. Afterwards, the optimal values of $-2\ln L_n$ in cross-validation patches can be summed up to 
compute the cross-validation score $C_{\rm cv}$ as a function of the regularization strength $\epsilon$.
In the end, the PSF solution $X_{\epsilon}$ that minimizes this cross-validation cost function will be selected as the optimal solution.

%\begin{algorithm} 
%\caption{The procedure for Inferring the Super-Resolution PSF}
%\begin{algorithmic}[1] \label{alg:supermean}

%\IF{$t=1:$}
%\STATE $\epsilon_t \gets \infty$
%\FOR{$n=1,...,N$}
%   \STATE // \emph{This can now be done in parallel for all i}
%
%   \STATE $b_{n}$ \gets \mathrm{median} \; $(y_{n})$
%   \STATE $f_{n}$ \gets $\sum_{i=1}^{N_pix} \big(y_{n,i} - b_{n}\big)$
%   \STATE \mathrm{Initialize} $\Delta_{n}$ with the 3 \times 3 polynomial method
%   \STATE $X_{n}$ \gets \mathrm{cubic \; spline} $(\Delta_n)[\big(y_{n,i} - b_{n}\big)/f_n]$
%\ENDFOR
%\STATE $X$ \gets $\sum_{n=1}^{N} X_{n]$%

%\ENDIF
%\IF{$t=2,...,N_{it}:$}
%\FOR{$i=1,...,N$}

%   \WHILE{$\rho(X,D)>\epsilon_t$}
%   \STATE Draw $\pars^{*}_{t}$ from $\{\pars_{t-1}\}$ with probabilities $\{w_{t-1}\}$
%   \STATE $\pars^{*}_{t} \gets K(\pars^{*}_{t},.)$
%   \STATE $X = f(\pars^{*}_{t})$
%   \ENDWHILE
%   \STATE $\pars^{(i)}_{t} \gets \pars^{*}_{t}$
%   \STATE $w^{(i)}_{t} \gets \pi(\pars^{(i)}_{t}) / \big(\sum\limits_{j=1}^{N}w_{t-1}^{(i)}K(\pars^{(j)}_{t-1},\pars^{(i)}_{t}) \big)$
%\ENDFOR
%\ENDIF

%\end{algorithmic}
%\end{algorithm}


\section{Results}\label{sec:hstresults}

\section{Summary}\label{sec:hstsummary}
In this work, we have presented the first generative forward model of the observations of every point sources in the rich $\hst$ $\wfc$ IR dataset. 
The point spread functions of $\wfc$ IR channels are the most undersampled amongst all $\hst$ channels. 
The exercise of making highly accurate measurements of the shapes of faint and poorly resolved galaxies, accurate and precise astrometry and photometry of point sources, 
correction of the variable sub-pixel response function ``flat-field'' of the telescope, and many other scientific applications require great knowledge of 
the PSF at a resolution higher than what is sampled by the $\wfc$ IR detectors. 

PSF estimation and accurate point source photometry on a crowded field has two main challenges. \emph{First}: a large fraction of the pixels may not be usable for modeling purposes. This could lead to  significant information loss. \emph{Second}: using pixels that receive photons from multiple sources in modeling the PSF can bias the final PSF estimate. 
Using a validation set containing many point sources in the crowded fields, we show that we can successfully use our technique to perform PSF-fitting. 
This allows us to make optimal use of all the pixels in $\wfc$ IR observations of crowded fields.

\acknowledgments
We thank Michael Blanton, Daniel Foreman-Mackey, and Jay Anderson for discussions related to this work.  

\bibliographystyle{yahapj}
\bibliography{references}

\appendix
\section{appendix section}

\end{document}
